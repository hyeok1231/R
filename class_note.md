#회귀모형= 함수적관계+(확률적 관계)
#함숫값은  평균값으로, 확률적 관계는 입실론 
#E(Y|X)= ax+x1,  입실론 = N(0,a*2)
#우리의 경우, 종속변수와 독립변수 만 알고있음. 
#y=b0+b1x 의 경우  b0, b1, 입실론(모수 입실론에 대한 추정값= 잔차e)은 우리가 추정해야 함.  

#따라서 추정해야 함 

함수를 그릴때 조건부하에서의, y값의 확률적 관계이므로 y값을 x축으로 하여 확률분포를 그릴 수 있음(사진 확인 )

신뢰구간에 따른 b_i 값은 다 다름.   
신뢰구간에 100개중 95개가 모수를 포함한다는 의미.(=신뢰구간)

y=b_0 + b_1x + e (b_0, b_1은 헷, 추정값임 )
b_0은 절편, b_1은 기울기.  추정값이므로 다를수 있음. 


값들을 추정하는 방법  
#LEAST ABSOLUTE METHOD (잔차 절댓값을 다 더했을 때 최소화 하는 추정값
) 
###LEAST SQUARE METHOD( 잔차*2의 합을 최소화.) 
#maximum liklihood method 


# 확률변수(임의 결과에 실수값으로 대응시켜주는 함수)   {G,T}-> R
# X = IF G OCCURS, 1
      IF T      :  -1
      
0<=P(X)<=1
P(X)의 합은 1

밀도함수의 경우  
어떤 X에대해서 X의 확률은 0보다 크다.
-무한~+무한  (최대치)의 합은 1  4


# E(X)= X에 대한 평균적인 값(기댓값) !=평균값 
E(X)  연속의 경우 인테그랄, X*F(x)DX 
이산의 경우  시그마, X*PX

E(g(x))= 인테그랄{  g(X)*F(x)DX}
g(X)= (X-E(X))*2
COV= E(g(X,Y))
E(X-E(x))(Y-E(Y))
####왜??  풀어보기 
E(XY)-E(x)E(Y)

#두 변수의 공분산이 의미하는 바 


10.06  수업내용 중요  '
X, Y , 확률에서    Y는 아무값이나 가질 수 있음.  확률(Z)에서 Y값이 나올 확률을 정의, (분포) 확률분포가 가장 큰 값을 이으면  모 회귀선 
##
#동분산성   확률값에 정규부포가 다 동일하다.  



#ㅈㄴ중요   
#슬라이드 24  단순회귀모형의 경우를 직접 손으로 도출   (ㅚ소제곱추정량)
#슬라이드 24  최소제곱추정량의 분산  단순회구모형의 경우를 직접 손으로 도출해보기 )  


###개중요'  이차형태란 변수벡터에서 중복을 허용하여 두개만 뽑아 다 더한 형태를 이차형태라 함.  예를 들며  (x1, x2, x3)가 존재할때  ax1^2 + ax1x2+ ax1x3+ ax2x3+ ax2^2+ ax3^2 (a는 계수이다.)


#행렬의 교환법칙은 성립하지 않으나 결합법칙은 성립함 

#추정량이 모수와 같아진다면  불편추정량이라고 부름.  

#### 행렬의 미분식  
x에 대해 미분  
Ax  = A
x'A = A'
x'Ax = x'(A+A')

왜 OLS 추정에서  양변에  전치행렬을 하는지 궁금함


#불편추정량  :  추정량이 모수와 같을 때, 그 추정량을 불편추정량이라고 함. 


#Residual Standard Error=13.3053 잔차 

lm  (y~x)  는 r에서  알아서  lm 에 y~x가 있으면  회귀분석식으로  알아들음ㄴ 

#ols  단순회귀모형, 다중회귀모형
estimate  intercept:  b0
estimate    x     :   b1(기울기)

t  value  절댓값이 2보다 크면  통계적 의미가 크다.    (크면 클수록)
pr  t  0.0보다 작으면(작으면 작을수록)  
std.err  최소제곱추정량의 공분산 

시그마*2 = 1/n-k    *   (잔차 제곱의 합)

#7-5 
edu.spd     0.2277  0.0639  3.5606   0.0011    
직관과 맞지않는 추정 값   ( 표본의 문제, 직관의 문제, 통계추정상의 오류 등)

#lm에서  별이 많으면 많을수록 통계적으로 의미있음 

######최우추정법에서 L(p)에서  ln을 취하는 이유는 x축과 y축을 바꿔서 p값을 더 쉽게 찾기 위해  ( p의 차수가 높기 떄문에, )  
#정규분포에 대한 가정 필수 
(왜?)

f(E1+E2+E3+...)= f(E1)*f(E2)...

R-Square=0.7899 #이 모형은 78%정도의  종속변수의 변동을 설명할 수 있음을 해석 할 수 있다. 

# Adjusted R-squared:  0.7666    조절계수,  항상 r스퀘어보다 작을 수 밖에 없음(페널티_조절이 들어갔으므로)   

AIC BIC 등  이런 적합도평가는 구하는 방법을 유도하기 보다  이런게 어떤 의미이구나로 짚고 가면 될듯 

#AIC 와 BIC가 가르키는 적합모델이 다를 수 도 있음 

통계학의 기초 PPT에 관련 내용 있음 

#귀무가설의 의미는 우리가 추정한 회귀분석이 의미없다고 가정하는 것

#//분산공분산 차이 기억안남 // 


#r=과제 3  행렬로 구해보기 b= (b0
                              b1)
                              
더미변수  =  값이 0 아님 1로 (True or False )


#유의수준 10%하에서, pr()dl  이0.1보다 작으면 통계적으로 유의함

유의수준 5%하에서, pr()dl  이0.05보다 작으면 통계적으로 유의함